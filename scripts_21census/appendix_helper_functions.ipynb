{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix - Helper Function Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "SRC_PATH = Path().resolve() / 'src'\n",
    "sys.path.append(str(SRC_PATH))\n",
    "\n",
    "from src.config import REPO_PATH, DATA_PATH, DATA_21_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2021 Census Microdata Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import osmnx as ox\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def census_microdata_filtering():\n",
    "    \"\"\"extract records from the whole census microdata with selected areas (inner london) and variables\"\"\"\n",
    "    origin_microdata_file = DATA_21_PATH / 'UKDA2021census.tab' # To be processed file path\n",
    "    filtered_microdata_file = DATA_21_PATH / 'census_microdata_2021_inner_london.csv'   # Output file path\n",
    "\n",
    "    # filter regions (including 13 boroughs in Inner London, referred to:\n",
    "    # https://www.london.gov.uk/programmes-strategies/planning/london-plan/the-london-plan-2021-online/annex-2-inner-and-outer-london-boroughs)\n",
    "    inner_london_borough_codes = [\n",
    "        \"E68000208\", \"E68000214\", \"E68000218\", \"E68000219\", \"E68000220\",\n",
    "        \"E68000226\", \"E68000227\", \"E68000229\", \"E68000230\", \"E68000235\",\n",
    "        \"E68000237\", \"E68000239\", \"E68000232\"] \n",
    "    \n",
    "    variable_rename_map = {\n",
    "        \"resident_id_m\":                \"resident_id\",\n",
    "        \"approx_social_grade\":          \"approximated_social_grade\",\n",
    "        \"economic_activity_status_15m\": \"economic_activity\",\n",
    "        \"employment_status\":            \"employment_status\",\n",
    "        \"english_proficiency_5a\":       \"english_proficiency\",\n",
    "        \"ethnic_group_tb_20b\":          \"ethnic_group\",\n",
    "        \"gltla22cd\":                    \"borough_code\",\n",
    "        \"hh_size_7a\":                   \"household_size\",\n",
    "        \"highest_qualification\":        \"highest_qualification\",\n",
    "        \"legal_partnership_status_7a\":  \"marital_status\",\n",
    "        \"number_of_cars_6a\":            \"number_of_cars_and_vans\",\n",
    "        \"resident_age_18m\":             \"age\",\n",
    "        \"sex\":                          \"sex\",\n",
    "    }\n",
    "\n",
    "\n",
    "    ddf_all = dd.read_table(origin_microdata_file, dtype={'fm_iol22cd': 'object'})\n",
    "    ddf_filtered = ddf_all[ddf_all[\"gltla22cd\"].isin(inner_london_borough_codes)]   # filter specific areas\n",
    "    ddf_filtered = ddf_filtered[list(variable_rename_map.keys())]                   # filter specific variables\n",
    "    ddf_filtered = ddf_filtered.rename(columns=variable_rename_map)                 # rename variables\n",
    "    df_filtered = ddf_filtered.compute()\n",
    "    df_filtered.to_csv(filtered_microdata_file, index=False)\n",
    "    \n",
    "    print(f'Filtered data successfully saved to {filtered_microdata_file}!')\n",
    "\n",
    "# Call the function\n",
    "census_microdata_filtering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LAD Population Feature Distribution Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import RES_STATIC, RES_SYN_POP_PATH\n",
    "import pandas as pd\n",
    "from src.get_marginal_distribution import marg_age_dist, marg_sex_dist,marg_ethnic_dist, marg_ecoact_dist, marg_car_dist, marg_leptnershp_dist\n",
    "from src.validation import freq_table, convert_freq_dict_to_vector, get_js_distance\n",
    "REF_label = {\n",
    "    'age': marg_age_dist(space_level='LAD'),\n",
    "    'sex': marg_sex_dist(space_level='LAD'),\n",
    "    'ethnic_group': marg_ethnic_dist(space_level='LAD'),\n",
    "    'economic_activity': marg_ecoact_dist(space_level='LAD'),\n",
    "    'number_of_cars_and_vans': marg_car_dist(space_level='LAD'),\n",
    "    'marital_status': marg_leptnershp_dist(space_level='LAD'),\n",
    "}\n",
    "CODE_map = pd.read_csv(RES_STATIC / 'Coding_Scheme_LMSOA_LAD.csv')\n",
    "CODE_area = CODE_map['LAD_CODE'].unique()\n",
    "\n",
    "check_instances = [\n",
    "                   '1e3',\n",
    "                #    '1e3', '2e3', '3e3', '4e3', '5e3', '6e3', '7e3', '8e3', '9e3',\n",
    "                   '1e4', '2e4', '3e4', '4e4', '5e4', '6e4', '7e4', '8e4', '9e4', \n",
    "                   '1e5', '2e5', '3e5', '4e5', '5e5', '6e5', '7e5', '8e5', '9e5',\n",
    "                   '1e6', '1.5e6', '2e6'] \n",
    "check_features = ['age', 'sex', 'ethnic_group', 'economic_activity', 'number_of_cars_and_vans', 'marital_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['age'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = ['0-15', '16-29', '30-49', '50+']\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Age Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Age Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_label.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Age\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['sex'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = ['Female', 'Male']\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Sex Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Sex Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ethnic_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Age\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['ethnic_group'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = probs_df.columns\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Ethnic Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Ethnic Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### economic_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Age\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['economic_activity'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = probs_df.columns\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Ecoact Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Ecoact Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number_of_cars_and_vans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Age\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['number_of_cars_and_vans'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = probs_df.columns\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Cars Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Cars Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Age\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "probs_df = REF_label['marital_status'][:14]  # In JS Matrix, each row represent one distribution\n",
    "probs = probs_df.to_numpy() \n",
    "\n",
    "# Calculate Jensen-Shannon Distribution Matrix to get the proximity of the frequency distribution\n",
    "n = len(probs)\n",
    "js_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        dist = round(jensenshannon(probs[i], probs[j]), 3)\n",
    "        js_matrix[i, j] = dist\n",
    "        js_matrix[j, i] = dist\n",
    "\n",
    "# print(\"Jensen-Shannon Distance Matrix:\")\n",
    "# print(js_matrix)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "labels = probs_df.index\n",
    "\n",
    "# left plot\n",
    "x = probs_df.columns\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 4))\n",
    "for col in labels:\n",
    "    ax1.plot(x, probs_df.loc[col], label=col)\n",
    "\n",
    "ax1.set_xlabel('Marital Group')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_title('Marital Group by Different Local Authority')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# right plot\n",
    "import seaborn as sns\n",
    "fig2, ax2 = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(js_matrix, xticklabels=labels, yticklabels=labels, cmap='coolwarm', annot=True, ax=ax2,\n",
    "            vmin=0, vmax=0.18)\n",
    "ax2.set_title('Jensen-Shannon Distance Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert from xlsx to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Change all xlsx to csvs under same file\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_xlsx_to_csv(folder_path):\n",
    "    \"\"\"\n",
    "    Convert all .xlsx files in the specified folder to .csv files,\n",
    "    keeping the original file names (only changing the extension).\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str or Path): Path to the folder containing .xlsx files\n",
    "    \"\"\"\n",
    "    folder = Path(folder_path)\n",
    "    xlsx_files = list(folder.glob(\"*.xlsx\"))\n",
    "\n",
    "    for xlsx_file in tqdm(xlsx_files, desc=\"Converting Progress\", total=len(xlsx_files)):\n",
    "        try:\n",
    "            # Read the Excel file (first sheet by default)\n",
    "            df = pd.read_excel(xlsx_file)\n",
    "\n",
    "            # Generate corresponding .csv file path\n",
    "            csv_file = xlsx_file.with_suffix(\".csv\")\n",
    "\n",
    "            # Save as CSV (without index column)\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"Converted: {xlsx_file.name} to {csv_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {xlsx_file.name}: {e}\")\n",
    "\n",
    "convert_xlsx_to_csv(DATA_21_PATH / 'statistic-summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect Encoding Scheme from Shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect Encoding Scheme of different levels of division\n",
    "import geopandas as gpd\n",
    "# Inner London Area shape file\n",
    "ILA_shp_file = DATA_PATH / 'gis-files' / 'Inner_London_Boundary' / 'Inner_London_lsoa.shp'\n",
    "ILA_gpd = gpd.read_file(ILA_shp_file)\n",
    "ILA_gpd.to_crs(epsg='4326', inplace=True)\n",
    "ILA_lmsoa_code = ILA_gpd[['lsoa21cd', 'msoa21cd', 'lad22cd', 'lad22nm']].copy()\n",
    "ILA_lmsoa_code.rename(columns={'lsoa21cd':'LSOA_CODE', 'msoa21cd':'MSOA_CODE', 'lad22cd':'LAD_CODE', 'lad22nm':'LAD_NAME'}, inplace=True)\n",
    "ILA_lmsoa_code.to_csv(DATA_PATH / 'gis-files' / 'Coding_Scheme_LMSOA_LAD.csv', index=False) # Save the coding scheme of different levels of administrative regions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Open Street Map for Landuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import osmnx as ox\n",
    "# import geopandas as gpd\n",
    "\n",
    "# place_name = \"London, UK\"\n",
    "\n",
    "# tags = {\"landuse\": True}\n",
    "# gdf = ox.features_from_place(place_name, tags)\n",
    "# gdf = gdf[gdf.geometry.type.isin([\"Polygon\", \"MultiPolygon\"])]\n",
    "# print(f\"Filtered to {len(gdf)} polygon features.\")\n",
    "\n",
    "# print(gdf[[\"landuse\", \"geometry\"]].head())\n",
    "\n",
    "# output_path = DATA_PATH / 'gis-files' / 'OSM_data' /\"london_landuse.shp\"\n",
    "# gdf.to_file(output_path, driver=\"ESRI Shapefile\")\n",
    "\n",
    "# print(f\"Save as Shapefile：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import osmnx as ox\n",
    "\n",
    "london_wards_shpfile = DATA_PATH / 'gis-files' / 'Inner_London_Boundary' / 'inner_london_lsoa.shp'\n",
    "gdf_london_wards = gpd.read_file(london_wards_shpfile)\n",
    "gdf_london_wards.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "\n",
    "london_polygon = unary_union(gdf_london_wards[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.ops import unary_union\n",
    "import osmnx as ox\n",
    "from osmnx.features import features_from_polygon\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_osm_data_london():\n",
    "    london_wards_shpfile = DATA_PATH / 'gis-files' / 'Inner_London_Boundary' / 'inner_london_lsoa.shp'\n",
    "    gdf_london_wards = gpd.read_file(london_wards_shpfile)\n",
    "    gdf_london_wards.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    london_polygon = unary_union(gdf_london_wards.geometry)\n",
    "\n",
    "    out_dir = DATA_PATH / 'gis-files' / 'OSM_data'\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    gdf_landuse = features_from_polygon(\n",
    "        london_polygon,\n",
    "        tags={\"landuse\": [\"residential\", \"retail\", \"commercial\"]}\n",
    "    )\n",
    "    if not gdf_landuse.empty:\n",
    "        gdf_landuse = gdf_landuse[[\"name\", \"landuse\", \"geometry\", \"type\"]]\n",
    "    gdf_landuse.to_file(str(out_dir / 'landuse.geojson'), driver='GeoJSON')\n",
    "\n",
    "    \n",
    "    gdf_buildings = features_from_polygon(\n",
    "        london_polygon,\n",
    "        tags={\"building\": [\"residential\"]}\n",
    "    )\n",
    "    gdf_buildings.to_file(str(out_dir / 'buildings.geojson'), driver='GeoJSON')\n",
    "\n",
    "    \n",
    "    G = ox.graph_from_polygon(\n",
    "        london_polygon,\n",
    "        custom_filter=\"['highway'~'motorway|trunk|primary|secondary|tertiary|residential']\"\n",
    "    )\n",
    "    ox.io.save_graph_geopackage(\n",
    "        G,\n",
    "        filepath=str(out_dir / 'road_network.gpkg'),\n",
    "        encoding='utf-8',\n",
    "        directed=False\n",
    "    )\n",
    "\n",
    "    print(f\"Saved to {out_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert geojson to shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "out_dir = DATA_PATH / 'gis-files' / 'OSM_data'\n",
    "\n",
    "# read GeoJSON file\n",
    "geojson_path = out_dir / 'landuse.geojson'\n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "print(\"Finish Conversion!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = DATA_PATH / 'gis-files' / 'OSM_data'\n",
    "gdf = gpd.read_file(out_dir / 'landuse.geojson')\n",
    "polygon_gdf = gdf[gdf.geometry.type.isin(['Polygon', 'MultiPolygon'])]\n",
    "polygon_gdf = polygon_gdf.reset_index(drop=True)\n",
    "polygon_gdf = polygon_gdf.set_crs(epsg=4326, allow_override=True)\n",
    "print(polygon_gdf.head())\n",
    "\n",
    "# Save Shapefile\n",
    "shp_output_path = out_dir / 'shp' / 'landuse.shp'  \n",
    "polygon_gdf.to_file(shp_output_path, driver='ESRI Shapefile')\n",
    "\n",
    "# gdf.to_file(\"landuse_fixed.shp\", driver=\"ESRI Shapefile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert gpkg to shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import RES_SYN_ORD_PATH, RES_STATIC\n",
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file(RES_SYN_ORD_PATH / \"synthetic_order_2e6_42.gpkg\", layer=\"syn_ord\")  # 如果gpkg里有多个layer，需指定\n",
    "gdf.to_file(RES_STATIC / 'Figures'/ \"Display_order.shp\", driver=\"ESRI Shapefile\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Using Sampling Directly from Syn Ord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation of Synthetic Orders - Order Feature\n",
    "\n",
    "Validation Data Source: [Online shopping behavior in the United Kingdom (UK)](https://www.statista.com/study/22395/online-shopping-in-the-united-kingdom-statista-dossier/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import RES_STATIC, RES_SYN_ORD_PATH\n",
    "\n",
    "REF_cate = pd.read_excel(RES_STATIC/'verify_order_category.xlsx', sheet_name='data')    # 1 - third party source\n",
    "\n",
    "check_features = ['Order_Category']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = [\n",
    "    1e6, 2e6, \n",
    "    1e5, 2e5, 3e5, 4e5, 5e5, 6e5, 7e5, 8e5, 9e5, \n",
    "    1e4, 2e4, 3e4, 4e4, 5e4, 6e4, 7e4, 8e4, 9e4, \n",
    "    1e3, 2e3, 3e3, 4e3, 5e3, 6e3, 7e3, 8e3, 9e3, \n",
    "    1e2, 2e2, 3e2, 4e2, 5e2, 6e2, 7e2, 8e2, \n",
    "    1e1, 2e1, 5e1, 8e1, \n",
    "    ]\n",
    "sample_sizes = list(map(int, sample_sizes))\n",
    "random_seeds = [i for i in range(20)] + [42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.validation import freq_table, convert_freq_dict_to_vector, get_js_distance\n",
    "\n",
    "res = []\n",
    "\n",
    "for seed in tqdm(random_seeds, desc=f'Checking Progress'):\n",
    "    instance = '2e6'\n",
    "    syn_ord_name = 'synthetic_order_' + instance + f'_{seed}.csv'\n",
    "    syn_ord_df = pd.read_csv(RES_SYN_ORD_PATH / syn_ord_name)\n",
    "\n",
    "    for sample_size in sample_sizes:\n",
    "        syn_ord_sample = syn_ord_df.sample(n=sample_size, replace=False)\n",
    "\n",
    "        check_res = {}\n",
    "        check_res['pop_size'] = sample_size\n",
    "        check_res['seed'] = seed\n",
    "\n",
    "        for feature in check_features:\n",
    "        \n",
    "            samples_X = syn_ord_sample[feature]\n",
    "            \n",
    "            freq_X = freq_table(samples_X)\n",
    "            freq_Y = REF_cate['Probability'].to_dict()\n",
    "\n",
    "            # Build the common support set (union of values)\n",
    "            support_1d = sorted(set(freq_X) | set(freq_Y))\n",
    "\n",
    "            # Convert freq dicts to aligned vectors\n",
    "            p_vec = convert_freq_dict_to_vector(freq_X, support_1d)\n",
    "            q_vec = convert_freq_dict_to_vector(freq_Y, support_1d)\n",
    "\n",
    "            # Compute JS distance\n",
    "            js_dist_1d = get_js_distance(p_vec, q_vec)\n",
    "            # print(js_dist_1d)\n",
    "\n",
    "            # js_var =  stat.variance(js_values_per_area)     # variance\n",
    "            check_res[feature] = js_dist_1d\n",
    "        \n",
    "        res.append(check_res)\n",
    "\n",
    "order_verify_df = pd.DataFrame(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'  # Times New Roman\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "df = order_verify_df\n",
    "\n",
    "# 1️⃣ category and width\n",
    "categories = np.sort(df['pop_size'].unique())\n",
    "positions = categories\n",
    "widths = categories/3\n",
    "\n",
    "# prepare data\n",
    "data = [df.loc[df['pop_size']==cat, \"Order_Category\"] for cat in categories]\n",
    "\n",
    "# 2️⃣ Main: violin plot\n",
    "parts = ax.violinplot(\n",
    "    dataset=data,\n",
    "    positions=positions,\n",
    "    widths=widths,\n",
    "    showmeans=False,\n",
    "    showmedians=False,\n",
    "    showextrema=False\n",
    ")\n",
    "\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('#4d8075')     # light green\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.5)\n",
    "\n",
    "# 3️⃣ Main: boxplot plot\n",
    "medians = []\n",
    "for i, cat_data in enumerate(data):\n",
    "    bp = ax.boxplot(\n",
    "        cat_data,\n",
    "        positions=[positions[i]],\n",
    "        widths=widths[i]*0.3,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='#335f69', color='black', linewidth=1),  # dark green\n",
    "        medianprops=dict(color='red', linewidth=2),\n",
    "        whiskerprops=dict(color='black', linewidth=1),\n",
    "        capprops=dict(color='black', linewidth=1)\n",
    "    )\n",
    "    # get median\n",
    "    median_val = bp['medians'][0].get_ydata()[0]\n",
    "    medians.append(median_val)\n",
    "\n",
    "# 4️⃣ Connect medians with a line\n",
    "ax.plot(positions, medians, color='red', linestyle=':', marker='o', label='Median Trend', alpha=0.5)\n",
    "\n",
    "# 5️⃣ set log x axis\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylim(0, 0.9)\n",
    "ax.set_xlim(5, 3e6)\n",
    "\n",
    "# 6️⃣ labels\n",
    "ax.set_xlabel(\"Synthetic Scale (pop_size)\", fontsize=14)\n",
    "ax.set_ylabel(\"Jenson-Shannon Divergence\", fontsize=14)\n",
    "ax.set_title('Violin and Boxplot of JSD for Synthetic Order Category', fontsize=14)\n",
    "\n",
    "# 7️⃣ Add grid\n",
    "ax.grid(which='major', axis='both', linestyle=':', linewidth=0.8, alpha=0.7)\n",
    "\n",
    "# 8️⃣ Add legend\n",
    "legend_elements = [\n",
    "    Patch(facecolor='#4d8075', edgecolor='black', alpha=0.5, label='Violin Plot'),\n",
    "    Patch(facecolor='#335f69', edgecolor='black', label='Boxplot'),\n",
    "    Line2D([0], [0], color='red', linestyle=':', lw=2, label='Median Trend')\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(RES_STATIC / 'Figures'/ \"jsd-ord.png\", dpi=600, bbox_inches='tight') \n",
    "# plt.savefig(RES_STATIC / 'Figures'/ \"jsd-ord.pdf\", bbox_inches='tight') \n",
    "# plt.savefig(RES_STATIC / 'Figures'/ \"poster-jsd-ord.png\", dpi=600, bbox_inches='tight') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc-dis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
